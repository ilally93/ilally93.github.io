---
layout: post
title: "HW5: Reflections"
date: 2019-09-03
---

      This morning I woke up to an article* sent from my mom about artificial
    intelligence being used in health care.  The timing of being sent the article 
    was interesting because of the articles we were meant to read talked some about 
    healthcare.  The article I was sent focused on AI sorting people with pneumonia 
    into low risk and high risk categories.  The sorting worked pretty well, except 
    for in the case of asthmatics.  The people with asthma were sorted into the low 
    risk category when diagnosed with asthma.
    
      Similarly, there were articles on radiation being misdosed in some of the 
    articles we were meant to read.  The problems in these medical cases is that 
    the software needs to be checked on by humans still.  Neither of these software 
    are/ were ready to be used in the healthcare field.  The AI with asthma is 
    still in the testing phase, which is good.  It seems like the radiation machine 
    was not tested correctly though.  It is likely that since the previous models 
    of the machines worked just fine, then testing may have been cut short.  
    These software weren't up to code on the resilience activities of recognition, 
    resistances, recovery, and reinstatement.
    
      The article "Why Software Projects Fail, and the Traps You Can Avoid That 
    Could Spell Disaster", lists insufficient testing as one of the problems.  
    The other "traps" mentioned are lack of time, poor planning, unclear 
    requirements, too many cooks in the kitchen, and poor project management.  
    The FBI Sentinel Project seemed to carry many of these traits that cause 
    software failure.
    
      The sentinel project went over budget, went over town, and even switched 
    contractors.  The articles about Sentinel were written in 2010, 2012, and 2014, 
    if that tells you anything about the time management.  Additionally, this 
    project was meant specifically for security, which is discussed in chapter 13 
    and 14.  The final problem that seems to be across all the software in the 
    articles was the lack of transparency after the radiation mishaps and the 
    lack of a working Sentinel project.
    
      There are obviously so many ways software projects can fail and keeping 
    an eye on the traps discussed.  Finally, if something does mess up, it is 
    the ethical duty of the software engineers to be transparent.
    
   *[article](https://www.smithsonianmag.com/innovation/will-artificial-intelligence-improve-health-care-for-everyone-180972758/?utm_source=facebook.com&utm_medium=socialmedia&fbclid=IwAR24FD7XQriiRi3WXcEwx_x-DFSfzM12auwrQt3Uh_3KH177CV-rjMSLPPA)
   
   Assigned Readings: 
   [1](http://www.cs.cofc.edu/~bowring/classes/csci%20362/docs/Therac25Accidents.html) [2](http://www.cs.cofc.edu/~bowring/classes/csci%20362/docs/The%20Radiation%20Boom%20-%20After%20Stroke%20Scans,%20Patients%20Face%20Serious%20Health%20Risks%20-%20NYTimes.com.pdf) [3](https://www.ic3.gov/media/2016/160317.aspx) [4](http://www.cs.cofc.edu/~bowring/classes/csci%20362/docs/levesonSoftwareAccidentsSpacecraft.pdf) [5](http://www.cs.cofc.edu/~bowring/classes/csci%20362/docs/SpectrumFBIcaseFileSytem.pdf) [6](http://www.washingtonpost.com/wp-dyn/content/article/2010/10/20/AR2010102006754.html) [7](https://www.pcmag.com/news/301010/years-late-and-millions-over-budget-fbis-sentinel-finally) [8](https://spectrum.ieee.org/riskfactor/computing/it/fbis-500-million-sentinel-case-management-system-still-has-major-operational-kinks-ig-reports) [9](https://www.entrepreneur.com/article/329019)
